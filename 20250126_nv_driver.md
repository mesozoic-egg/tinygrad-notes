# How Tinygrad's Nvidia driver works, and how it hacked p2p on 4090

Communicating with GPUs can be broken down into three parts. The first is the application code. For example, some
python or C++ code that does back propagation and matrix multiplication. This includes DL framework like tinygrad,
pytorch. It may also be some vendor provided libraries like CUBLAS. These high level code then calls into a library
that actually communicate with the GPU and does all the work. This library is also known as a driver.

Driver can be divided into two categories. The first is the userspace driver. They interface directly with high level
application code, and communicates with the linux operating system (OS), commonly by issuing `ioctl` signals. The OS
then intercepts these signals, and send them over to the second category, the *kernel driver*, or kernel modules.
Kernel driver does the actual communication with the hardware. 

Turns out, p2p was disabled on the userspace driver level. In other words, simply by issuing the right `ioctl` signals
(written in Python!), we can re-enable this functionality!

## From CUDA to driver

CUDA offers a nice abstraction for parallel programming, so you never had to deal with the driver complexity. For example,
doing some vector addition in parallel is as simple as:

```c++
__global__ void add_vectors(double *a, double *b, double *c)
{
    int id = blockDim.x * blockIdx.x + threadIdx.x;
    c[id] = a[id] + b[id];
}

int main()
{
    // ...
    cudaMemcpy(d_A, A, bytes, cudaMemcpyHostToDevice); 
    // ...
    add_vectors<<< blk_in_grid, thr_per_blk >>>(d_A, d_B, d_C);
}
```

Compile this with `nvcc`, then you have an executable that does everything. The functionality we used are referred to
as runtime API (`cudaMemcpy`, `<<<>>>` syntax). In contrast, we can go one level deeper by using the kernel API. This
is also the userspace driver I previously mentioned.

```c++
#include <cuda.h> // This is where kernel api resides
int main()
{
  cuInit(0);
  CUdevice pdev;
  cuDeviceGet(&pdev, 1); // TODO: the hook only works with 1 here at work
}
```

Remember I said that a common way for userspace driver to communicate with GPU is via `ioctl` signals? All `cuInit` 
does is simply sending a struct to the OS, and we can write a sniffer to detect them!

The way a sniffer works is simply wrap around the existing library that was used to issue ioctl signals. For example,
calling ioctl in C++ looks like this:

```c++
#include <sys/ioctl.h>

ioctl();
```

We can write our own version of it and log the input arguments, then pass everything through, into the original `ioctl`:

```c++
```

This is the sniffer repo written by geohot, I have made some changes in the fork so you can run it as well.

## Sniffing

Let's look at the result we have gathered from the vector addition.